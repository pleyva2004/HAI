# Complete Application Flow

## Overview

This document describes the end-to-end flow of the SAT Question Generator application, from API request to final question delivery.

---

## Entry Point: API Request

**Endpoint:** `POST /api/v1/generate`

**Input:**
- Text description (requirements)
- Optional file upload (PDF/image)
- Number of questions requested
- Optional target difficulty
- Optional preference flags

**Output:**
- Generated questions (list)
- Metadata (counts, scores, mix)
- Any errors encountered

---

## Workflow Pipeline

The application uses a **6-node LangGraph workflow** that processes requests sequentially:

```
[OCR] → [Analyze] → [Search] → [Generate] → [Validate] → [Filter] → [Output]
```

---

## Node 1: OCR Extraction

**Purpose:** Extract text and structure from uploaded files

**Process:**
- If file provided: Extract text using DeepSeek-OCR
- If no file: Use text description directly
- Preserve question structure (markdown, tables, lists)

**Output:** Extracted text added to state

**Services Used:**
- OCR Service (DeepSeek-OCR model)

---

## Node 2: Analysis

**Purpose:** Understand requirements and extract style characteristics

**Process:**
- Parse user requirements from text
- Identify category (algebra, geometry, etc.)
- Determine target difficulty
- Extract style profile from examples (if provided)
  - Word count patterns
  - Vocabulary level
  - Number complexity
  - Context type
  - Question structure

**Output:**
- Question analysis (category, difficulty, characteristics)
- Style profile (if examples available)

**Services Used:**
- LLM Service (for requirement parsing)
- Style Analyzer (for style extraction)

---

## Node 3: Question Bank Search

**Purpose:** Find similar real SAT questions from database

**Process:**
- Generate embedding from requirements
- Vector similarity search in PostgreSQL
- Filter by category and difficulty range
- Retrieve top candidates

**Output:** List of real SAT questions (templates)

**Services Used:**
- Question Bank Service (PostgreSQL + pgvector)
- Embedding model (sentence transformers)

---

## Node 4: Generation

**Purpose:** Create new questions using AI models

**Process:**
- Plan hybrid mix (50% real, 50% generated by default)
- For real questions: Use templates from search
- For generated questions:
  - Create variations from real templates (if available)
  - Generate synthetic questions from scratch
  - Apply style profile to match examples
- Use multiple LLMs (GPT-4o + Claude) for diversity

**Output:** Pool of candidate questions (real + generated)

**Services Used:**
- LLM Service (GPT-4o, Claude)
- Style Matcher (for style application)

---

## Node 5: Validation

**Purpose:** Ensure questions are correct and clear

**Process:**
- Validate each generated question using multiple models
- Check answer correctness
- Verify question clarity
- Require unanimous approval from all validators
- Track agreement scores

**Output:** Validated questions (only those passing all checks)

**Services Used:**
- LLM Service (multi-model validation)

---

## Node 6: Quality Filtering

**Purpose:** Apply all quality filters and select final questions

**Process:**
- **Style Matching:** Score questions against style profile, filter below threshold
- **Difficulty Calibration:** Predict difficulty using ML model, filter to target range
- **Anti-Duplication:** Remove semantic and structural duplicates
- **Ranking:** Sort by style match score
- **Selection:** Choose final questions preserving requested mix (real vs generated)

**Output:** Final question set with metadata

**Services Used:**
- Style Matcher
- Difficulty Calibrator (ML model)
- Duplication Detector

---

## Final Output

**Response Structure:**
```json
{
  "questions": [
    {
      "id": "...",
      "question": "...",
      "choices": {...},
      "correct_answer": "...",
      "difficulty": 65.0,
      "category": "algebra",
      "is_real": false
    }
  ],
  "metadata": {
    "total_questions": 5,
    "real_questions": 2,
    "generated_questions": 3,
    "avg_difficulty": 62.5,
    "avg_style_match": 0.87,
    "target_mix": {"real": 2, "generated": 3}
  },
  "errors": []
}
```

---

## Supporting Services

### Question Bank Service
- **Storage:** PostgreSQL with pgvector extension
- **Function:** Vector similarity search, category filtering
- **Used in:** Search node

### LLM Service
- **Models:** GPT-4o (primary), Claude Sonnet 4 (validation)
- **Functions:** Generation, validation, analysis
- **Used in:** Analyze, Generate, Validate nodes

### Style Analyzer & Matcher
- **Function:** Extract and match style characteristics
- **Used in:** Analyze, Generate, Filter nodes

### Difficulty Calibrator
- **Model:** Random Forest (ML)
- **Function:** Predict difficulty (0-100 scale)
- **Used in:** Filter node

### Duplication Detector
- **Methods:** Semantic similarity + structural fingerprinting
- **Function:** Detect and remove duplicates
- **Used in:** Filter node

### OCR Service
- **Model:** DeepSeek-OCR
- **Function:** Extract text from PDFs/images
- **Used in:** OCR node

---

## Error Handling

- Each node handles errors gracefully
- Errors are collected in state
- Workflow continues even if individual steps fail
- Fallback mechanisms at each stage

---

## State Management

The workflow maintains a single `GraphState` object that flows through all nodes:

**Input State:**
- Description, file path, parameters

**Intermediate State:**
- Extracted text, analysis, style profile
- Real questions, generated candidates
- Validated questions

**Output State:**
- Final questions, metadata, errors

---

## Key Features Applied

1. **Style Matching:** Ensures generated questions match example style
2. **Difficulty Calibration:** ML-based difficulty prediction
3. **Anti-Duplication:** Prevents repetitive questions
4. **Multi-Model Validation:** Requires unanimous approval
5. **Hybrid Generation:** Mix of real and AI-generated questions

---

## Performance Characteristics

- **Typical Flow Time:** <30 seconds for 10 questions
- **Bottlenecks:** LLM API calls, database queries
- **Optimizations:** Async operations, batch processing, connection pooling

---

## Alternative Endpoints

### Search Questions
- **Endpoint:** `POST /api/v1/search`
- **Flow:** Direct database query (bypasses workflow)

### Validate Question
- **Endpoint:** `POST /api/v1/validate`
- **Flow:** Single validation check (bypasses workflow)

### Get Question
- **Endpoint:** `GET /api/v1/questions/{id}`
- **Flow:** Direct database lookup

---

**Last Updated:** Based on Implementation Session Log (November 2024)

